{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.思考在自然语言处理中如何发掘模型的可解释性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建模前：选用可解释性模型，如：决策树模型、线性回归、逻辑回归、广义线性回归、广义加性模型、贝叶斯实例模型等\n",
    "\n",
    "建模后：使用可解释性方法，主要是针对具有黑箱性质的深度学习模型而言的，主要分为以下几类的工作：隐层分析方法、 模拟/代理模型、敏感性分析方法\n",
    "\n",
    "可视化：深度学习模型的可解释性通常不强，但我们可以通过一些可视化工具对其进行理解。例如Tensor2Tensor提供了出色的工具对注意力进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.在Seq2Seq和注意力机制中如何可视化模型细节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq-Vis 以可视化的方式呈现出了序列到序列模型翻译的每一步，这样用户就能像查找规则表一样来找出机器翻译翻译错误的原因。\n",
    "\n",
    "attention map，使用注意力机制实现文本分类，我们需要观察每一个样本中，模型的重心放在哪里了，就是观察到权重最大的token，比如热力图seaborn.heatmap进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.对抗样本能否运用到自然语言处理模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同于图像领域，文本数据的离散特性使得众多研究集中于直接对文本序列进行对抗攻击（对文本序列进行，增删，修改等）。除了直接加在文本序列上的对抗扰动方法外，还可以通过在词向量上添加连续扰动的方式进行对抗攻击。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.复现Kaggle心脏病数据集冠军kernel，理解所用的模型可解释性技巧\n",
    "写成博客提交即可，markdown和word均可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转载自https://zhuanlan.zhihu.com/p/114353306\n",
    "\n",
    "主要用了以下工具\n",
    "- seaborn：统计数据可视化\n",
    "- ELI5：帮助调试机器学习分类器并解释它们的预测\n",
    "- SHAP：Python的可解释机器学习库\n",
    "- PDPbox：可视化某些功能对任何监督学习算法的模型预测的影响。\n",
    "- export_graphviz：随机森林可视化\n",
    "- ROC：模型评估\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
